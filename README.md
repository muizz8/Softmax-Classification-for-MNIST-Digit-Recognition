# ğŸ–¥ï¸ Softmax Classification for MNIST Digit Recognition

## ğŸ§¾ Project Overview  
This project demonstrates a **Softmax Classifier** for handwritten digit recognition using PyTorch, trained on the MNIST dataset. It includes implementations of Softmax classification in one dimension and a multi-class classification for handwritten digits.

## âœ¨ Key Features  
- ğŸ§® Softmax classification implementation  
- ğŸ“‚ MNIST dataset loading and preprocessing  
- ğŸš€ Model training and evaluation  
- ğŸ“Š Visualization of model parameters and results  

## âš™ï¸ Prerequisites  
- ğŸ Python 3.8+  
- ğŸ”¥ PyTorch  
- ğŸ“‰ Matplotlib  
- ğŸ–¼ï¸ Torchvision  

## ğŸ“¥ Installation  
```bash  
git clone https://github.com/muizz8/Softmax-Classification-for-MNIST-Digit-Recognition.git  
cd Softmax-Classification-for-MNIST-Digit-Recognition  
pip install torch torchvision matplotlib  
```  

## ğŸ“‚ Project Structure  
- `softmax_classifier.ipynb`: Main implementation of Softmax classification  

## ğŸ§© Key Components  
### ğŸ§  Softmax Classifier  
- Uses a **linear layer** for classification  
- Applies **Cross-Entropy Loss**  
- **Stochastic Gradient Descent (SGD)** optimizer  

### ğŸ“Š Visualization  
- Parameter visualization of trained model  
- Loss and accuracy tracking  
- Misclassification analysis  

## ğŸš€ Usage  
```python  
# Train the model  
model = SoftMax(input_size=784, output_size=10)  
train_model(epochs=10)  

# Evaluate and visualize  
PlotParameters(model)  
```  

## ğŸ“ˆ Results  
- âœ… Trained on MNIST dataset  
- ğŸ“‰ Visualizes model learning process  
- âŒ Shows misclassified and correctly classified samples  

## ğŸ™Œ Acknowledgments  
- ğŸ“š **MNIST Dataset**  
- ğŸ”¥ **PyTorch Team**
